{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dae80ab",
   "metadata": {},
   "source": [
    "# Resonator Networks\n",
    "\n",
    "The resonator network is an exciting new neural network design that is capable of solving challenging computational problems. The resonator network is unlike most neural networks in AI and in computational neuroscience. \n",
    "\n",
    "The resonator is for solving combinatorial search problems or factorization problems. We believe that many problems in perception and cognition are of this variety and that these problems aren't suitable for standard deep learning neural networks. Factorization problems can be memorized, but they do not generalize in the same way as standard pattern matching or classification problems. \n",
    "\n",
    "The architecture of the resonator network also includes an operation between neural populations that is very unfamiliar to both deep learning and computational neuroscience: the binding operation. The binding operation is a way of expressing combinatoric conjunctions of features into a vector space. This is what gives VSA flexibility to express data structures in neural activity. \n",
    "\n",
    "The opposite of binding is factorization. This relates to many fundamental problems in computer science, like the factorization of prime numbers and other combinatorial NP problems. These problems are challenging due to their scaling and complexity, but are not really conceptually hard for a computer to solve, they just require a lot of computational work. In fact, algorithmically, these problems are some of the easiest -- you just have to brute force guess and check all possible factors to decide which factors are present in a given factorization problem. \n",
    "\n",
    "The resonator network's approach to solving such problems uses the VSA principle of superposition. With superposition, neural populations can hold multiple guesses for one of the factors and test them simultaneously. However, the price of simultaneous inference is crosstalk noise. The resonator network performs such an inference step iteratively, and uses attractor dynamics to \"clean-up\" the result of each inference step. By iteratively performing inference and clean-up the resonator network searches through the combinatoric solution space, and when it finds the right combination the dynamics rapidly converge to a stable state.\n",
    "\n",
    "## Resonator Networks 1: An efficient solution for factorization of distributed data structures\n",
    "\n",
    "![resonator_circuit_diagram](resonator_circuit_diagram.png)\n",
    "\n",
    "### Summary \n",
    "\n",
    "In the first resonator network paper, we explain the concept behind the resonator network -- search in superposition. We describe how VSA can be used to create data structures, like a tree, and show that fully manipulating this data structure often leads to a combinatoric search problem. For a tree data structure, the problem is to find a certain item that is in the tree, and we describe how tree search can be done with the resonator network. \n",
    "\n",
    "We also describe how simple geometric transformations onto objects are fundamentally bindings between the object shape and its transformation. This means that understanding a simple scene, of e.g., numbers positioned in different locations, can indeed be expressed as a factorization problem. \n",
    "\n",
    "### Links\n",
    "\n",
    "<a href=\"https://redwood.berkeley.edu/wp-content/uploads/2020/11/frady2020resonator.pdf\"> PDF: Resonator networks 1 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1f68e",
   "metadata": {},
   "source": [
    "## Resonator Networks 2: Factorization performance and scaling\n",
    "\n",
    "\n",
    "![resonator_performance](resonator_performance_comparison.png)\n",
    "\n",
    "### Summary\n",
    "\n",
    "In the second paper on resonator networks, we examine the empirical performance on a standardized vector factorization problem and compare the resonator network to conventional optimization methods. We show that the resonator network is solving much more complex problems than what conventional approaches can handle. \n",
    "\n",
    "We speculate that this performance improvement is due to the fact that the resonator network does not have a conventional energy landscape. Unlike the optimization methods, which always follow the local gradient of an energy landscape, the resonator network has dynamics that cannot be described by an energy or lyapunov function. This means that there are poentially chaotic and cyclic states in the network, and it cannot be guaranteed to converge. However, the performance limitation of most optimization methods is due to getting stuck in local-minima. \n",
    "\n",
    "While the resonator network cannot be mathematically guaranteed to converge, we see empirically that it does converge to the right answer with high-probability if the problem size is under the network's operational capacity. The operational capacity is based on the total number of combinations in the search space. We show that as the size of the resonator network scales up, the operational capacity of the network increases quadratically.\n",
    "\n",
    "### Links\n",
    "<a href=\"https://redwood.berkeley.edu/wp-content/uploads/2020/11/kent2020resonator.pdf\"> PDF: Resonator networks 2 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e823b45",
   "metadata": {},
   "source": [
    "## Integer Factorization with Compositional Distributed Representations\n",
    "\n",
    "![integer_factorization](res_int_factor-220319.png)\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "Factoring integers is a well-known problem in computer science and in fact it serves as the back-bone of encryption. This is one of many problems that are \"NP\" or non-polynomial, which means that you effectively have to use brute-force methods to find the answer. As the problems get harder and harder, these brute-force methods scale exponentially in complexity, which can be virutally impossible to solve.\n",
    "\n",
    "The problem of integer factorization is fundamentally related to the problem of vector factorization that the resonator network can solve. In this paper, we explain new methods for mapping integers onto VSA vectors based on [fractional power encodings](). The key is that through this method we can generate VSA vectors that represent integers, and, importantly, the binding of vectors creates a vector representation that is the product of the integers. This means that by solving vector factorization, we can solve integer factorization.\n",
    "\n",
    "We explain how to set-up the resonator network to solve the factorization of semi-primes and other composite numbers and measure the performance and scaling empirically. \n",
    "\n",
    "\n",
    "### Links\n",
    "\n",
    "[arXiv paper](http://arxiv.org/abs/2203.00920)\n",
    "\n",
    "[Factoring semi primes demo](res_semi_primes-220216.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbe491",
   "metadata": {},
   "source": [
    "<!--\n",
    "\n",
    "## Simple scene understanding with the resonator network\n",
    "\n",
    "[Template matching with resonator network](resonator_template.ipynb)\n",
    "\n",
    "-->\n",
    "\n",
    "<!--\n",
    "<a href=\"https://nbviewer.jupyter.org/url/epaxon.github.io/resonator-template-200915.ipynb\"> Resonator network with template letter scene </a>\n",
    "-->\n",
    "\n",
    "<!--\n",
    "## Utils\n",
    "[It's dangerous to go alone!](res_utils.py)\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbdfc40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
