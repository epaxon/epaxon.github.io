
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Resonator Networks &#8212; Neuromorphic Algorithms Research</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Factorization of shape, color and location" href="resonator_template.html" />
    <link rel="prev" title="Sparse binding demo – What’s the dollar of mexico?" href="sparse_binding_demo.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/neural_circuit.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Neuromorphic Algorithms Research</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../index.html">
   Neuromorphic Algorithms Research
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About me
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../about_me.html">
   E. Paxon Frady
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Research
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="spiking_networks.html">
   Spiking Neural Networks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="tpam_demo.html">
     Threshold Phasor Associative Memory
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="theoretical_neuroscience.html">
   Theoretical Neuroscience
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="sparse_binding_demo.html">
     Sparse binding demo – What’s the dollar of mexico?
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   Resonator Networks
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="resonator_template.html">
     Factorization of shape, color and location
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="res_semi_primes-220216.html">
     Factoring semi-primes with the resonator network
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Tutorials/computational_neuroscience.html">
   Computational Neuroscience
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Tutorials/spiking_basics_brian2.html">
     Rate-coding with Integrate-and-Fire neurons
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Tutorials/connecting_if_neurons.html">
     Connecting IFR theory to connectionism
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/Research/resonator_networks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Research/resonator_networks.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures">
   Resonator Networks 1: An efficient solution for factorization of distributed data structures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#links">
     Links
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resonator-networks-2-factorization-performance-and-scaling">
   Resonator Networks 2: Factorization performance and scaling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Links
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integer-factorization-with-compositional-distributed-representations">
   Integer Factorization with Compositional Distributed Representations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Links
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <!-- Table of contents that is only displayed when printing the page -->
    <div id="jb-print-docs-body" class="onlyprint">
        <h1>Resonator Networks</h1>
        <!-- Table of contents -->
        <div id="print-main-content" class="row">
            <div class="col-12 col-md-12 pl-md-5 pr-md-5">
            <div id="jb-print-toc">
                
                <div>
                    <h2> Contents </h2>
                </div>
                <nav aria-label="Page">
                    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures">
   Resonator Networks 1: An efficient solution for factorization of distributed data structures
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#links">
     Links
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#resonator-networks-2-factorization-performance-and-scaling">
   Resonator Networks 2: Factorization performance and scaling
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Links
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#integer-factorization-with-compositional-distributed-representations">
   Integer Factorization with Compositional Distributed Representations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     Summary
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     Links
    </a>
   </li>
  </ul>
 </li>
</ul>

                </nav>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="resonator-networks">
<h1>Resonator Networks<a class="headerlink" href="#resonator-networks" title="Permalink to this headline">¶</a></h1>
<p>The resonator network is an exciting new neural network design that is capable of solving challenging computational problems. The resonator network is unlike most neural networks in AI and in computational neuroscience.</p>
<p>The resonator is for solving combinatorial search problems or factorization problems. We believe that many problems in perception and cognition are of this variety and that these problems aren’t suitable for standard deep learning neural networks. Factorization problems can be memorized, but they do not generalize in the same way as standard pattern matching or classification problems.</p>
<p>The architecture of the resonator network also includes an operation between neural populations that is very unfamiliar to both deep learning and computational neuroscience: the binding operation. The binding operation is a way of expressing combinatoric conjunctions of features into a vector space. This is what gives VSA flexibility to express data structures in neural activity.</p>
<p>The opposite of binding is factorization. This relates to many fundamental problems in computer science, like the factorization of prime numbers and other combinatorial NP problems. These problems are challenging due to their scaling and complexity, but are not really conceptually hard for a computer to solve, they just require a lot of computational work. In fact, algorithmically, these problems are some of the easiest – you just have to brute force guess and check all possible factors to decide which factors are present in a given factorization problem.</p>
<p>The resonator network’s approach to solving such problems uses the VSA principle of superposition. With superposition, neural populations can hold multiple guesses for one of the factors and test them simultaneously. However, the price of simultaneous inference is crosstalk noise. The resonator network performs such an inference step iteratively, and uses attractor dynamics to “clean-up” the result of each inference step. By iteratively performing inference and clean-up the resonator network searches through the combinatoric solution space, and when it finds the right combination the dynamics rapidly converge to a stable state.</p>
<div class="section" id="resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures">
<h2>Resonator Networks 1: An efficient solution for factorization of distributed data structures<a class="headerlink" href="#resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures" title="Permalink to this headline">¶</a></h2>
<p><img alt="resonator_circuit_diagram" src="../_images/resonator_circuit_diagram.png" /></p>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>In the first resonator network paper, we explain the concept behind the resonator network – search in superposition. We describe how VSA can be used to create data structures, like a tree, and show that fully manipulating this data structure often leads to a combinatoric search problem. For a tree data structure, the problem is to find a certain item that is in the tree, and we describe how tree search can be done with the resonator network.</p>
<p>We also describe how simple geometric transformations onto objects are fundamentally bindings between the object shape and its transformation. This means that understanding a simple scene, of e.g., numbers positioned in different locations, can indeed be expressed as a factorization problem.</p>
</div>
<div class="section" id="links">
<h3>Links<a class="headerlink" href="#links" title="Permalink to this headline">¶</a></h3>
<p><a href="https://redwood.berkeley.edu/wp-content/uploads/2020/11/frady2020resonator.pdf"> PDF: Resonator networks 1 </a></p>
</div>
</div>
<div class="section" id="resonator-networks-2-factorization-performance-and-scaling">
<h2>Resonator Networks 2: Factorization performance and scaling<a class="headerlink" href="#resonator-networks-2-factorization-performance-and-scaling" title="Permalink to this headline">¶</a></h2>
<p><img alt="resonator_performance" src="../_images/resonator_performance_comparison.png" /></p>
<div class="section" id="id1">
<h3>Summary<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>In the second paper on resonator networks, we examine the empirical performance on a standardized vector factorization problem and compare the resonator network to conventional optimization methods. We show that the resonator network is solving much more complex problems than what conventional approaches can handle.</p>
<p>We speculate that this performance improvement is due to the fact that the resonator network does not have a conventional energy landscape. Unlike the optimization methods, which always follow the local gradient of an energy landscape, the resonator network has dynamics that cannot be described by an energy or lyapunov function. This means that there are poentially chaotic and cyclic states in the network, and it cannot be guaranteed to converge. However, the performance limitation of most optimization methods is due to getting stuck in local-minima.</p>
<p>While the resonator network cannot be mathematically guaranteed to converge, we see empirically that it does converge to the right answer with high-probability if the problem size is under the network’s operational capacity. The operational capacity is based on the total number of combinations in the search space. We show that as the size of the resonator network scales up, the operational capacity of the network increases quadratically.</p>
</div>
<div class="section" id="id2">
<h3>Links<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><a href="https://redwood.berkeley.edu/wp-content/uploads/2020/11/kent2020resonator.pdf"> PDF: Resonator networks 2 </a></p>
</div>
</div>
<div class="section" id="integer-factorization-with-compositional-distributed-representations">
<h2>Integer Factorization with Compositional Distributed Representations<a class="headerlink" href="#integer-factorization-with-compositional-distributed-representations" title="Permalink to this headline">¶</a></h2>
<p><img alt="integer_factorization" src="../_images/res_int_factor-220319.png" /></p>
<div class="section" id="id3">
<h3>Summary<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Factoring integers is a well-known problem in computer science and in fact it serves as the back-bone of encryption. This is one of many problems that are “NP” or non-polynomial, which means that you effectively have to use brute-force methods to find the answer. As the problems get harder and harder, these brute-force methods scale exponentially in complexity, which can be virutally impossible to solve.</p>
<p>The problem of integer factorization is fundamentally related to the problem of vector factorization that the resonator network can solve. In this paper, we explain new methods for mapping integers onto VSA vectors based on <span class="xref myst">fractional power encodings</span>. The key is that through this method we can generate VSA vectors that represent integers, and, importantly, the binding of vectors creates a vector representation that is the product of the integers. This means that by solving vector factorization, we can solve integer factorization.</p>
<p>We explain how to set-up the resonator network to solve the factorization of semi-primes and other composite numbers and measure the performance and scaling empirically.</p>
</div>
<div class="section" id="id4">
<h3>Links<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://arxiv.org/abs/2203.00920">arXiv paper</a></p>
<p><a class="reference internal" href="res_semi_primes-220216.html"><span class="doc std std-doc">Factoring semi primes demo</span></a></p>
<!--

## Simple scene understanding with the resonator network

[Template matching with resonator network](resonator_template.ipynb)

-->
<!--
<a href="https://nbviewer.jupyter.org/url/epaxon.github.io/resonator-template-200915.ipynb"> Resonator network with template letter scene </a>
-->
<!--
## Utils
[It's dangerous to go alone!](res_utils.py)

--></div>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Research"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </div>
        </div>
    </div>
    <div id="main-content" class="row noprint">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="resonator-networks">
<h1>Resonator Networks<a class="headerlink" href="#resonator-networks" title="Permalink to this headline">¶</a></h1>
<p>The resonator network is an exciting new neural network design that is capable of solving challenging computational problems. The resonator network is unlike most neural networks in AI and in computational neuroscience.</p>
<p>The resonator is for solving combinatorial search problems or factorization problems. We believe that many problems in perception and cognition are of this variety and that these problems aren’t suitable for standard deep learning neural networks. Factorization problems can be memorized, but they do not generalize in the same way as standard pattern matching or classification problems.</p>
<p>The architecture of the resonator network also includes an operation between neural populations that is very unfamiliar to both deep learning and computational neuroscience: the binding operation. The binding operation is a way of expressing combinatoric conjunctions of features into a vector space. This is what gives VSA flexibility to express data structures in neural activity.</p>
<p>The opposite of binding is factorization. This relates to many fundamental problems in computer science, like the factorization of prime numbers and other combinatorial NP problems. These problems are challenging due to their scaling and complexity, but are not really conceptually hard for a computer to solve, they just require a lot of computational work. In fact, algorithmically, these problems are some of the easiest – you just have to brute force guess and check all possible factors to decide which factors are present in a given factorization problem.</p>
<p>The resonator network’s approach to solving such problems uses the VSA principle of superposition. With superposition, neural populations can hold multiple guesses for one of the factors and test them simultaneously. However, the price of simultaneous inference is crosstalk noise. The resonator network performs such an inference step iteratively, and uses attractor dynamics to “clean-up” the result of each inference step. By iteratively performing inference and clean-up the resonator network searches through the combinatoric solution space, and when it finds the right combination the dynamics rapidly converge to a stable state.</p>
<div class="section" id="resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures">
<h2>Resonator Networks 1: An efficient solution for factorization of distributed data structures<a class="headerlink" href="#resonator-networks-1-an-efficient-solution-for-factorization-of-distributed-data-structures" title="Permalink to this headline">¶</a></h2>
<p><img alt="resonator_circuit_diagram" src="../_images/resonator_circuit_diagram.png" /></p>
<div class="section" id="summary">
<h3>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h3>
<p>In the first resonator network paper, we explain the concept behind the resonator network – search in superposition. We describe how VSA can be used to create data structures, like a tree, and show that fully manipulating this data structure often leads to a combinatoric search problem. For a tree data structure, the problem is to find a certain item that is in the tree, and we describe how tree search can be done with the resonator network.</p>
<p>We also describe how simple geometric transformations onto objects are fundamentally bindings between the object shape and its transformation. This means that understanding a simple scene, of e.g., numbers positioned in different locations, can indeed be expressed as a factorization problem.</p>
</div>
<div class="section" id="links">
<h3>Links<a class="headerlink" href="#links" title="Permalink to this headline">¶</a></h3>
<p><a href="https://redwood.berkeley.edu/wp-content/uploads/2020/11/frady2020resonator.pdf"> PDF: Resonator networks 1 </a></p>
</div>
</div>
<div class="section" id="resonator-networks-2-factorization-performance-and-scaling">
<h2>Resonator Networks 2: Factorization performance and scaling<a class="headerlink" href="#resonator-networks-2-factorization-performance-and-scaling" title="Permalink to this headline">¶</a></h2>
<p><img alt="resonator_performance" src="../_images/resonator_performance_comparison.png" /></p>
<div class="section" id="id1">
<h3>Summary<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>In the second paper on resonator networks, we examine the empirical performance on a standardized vector factorization problem and compare the resonator network to conventional optimization methods. We show that the resonator network is solving much more complex problems than what conventional approaches can handle.</p>
<p>We speculate that this performance improvement is due to the fact that the resonator network does not have a conventional energy landscape. Unlike the optimization methods, which always follow the local gradient of an energy landscape, the resonator network has dynamics that cannot be described by an energy or lyapunov function. This means that there are poentially chaotic and cyclic states in the network, and it cannot be guaranteed to converge. However, the performance limitation of most optimization methods is due to getting stuck in local-minima.</p>
<p>While the resonator network cannot be mathematically guaranteed to converge, we see empirically that it does converge to the right answer with high-probability if the problem size is under the network’s operational capacity. The operational capacity is based on the total number of combinations in the search space. We show that as the size of the resonator network scales up, the operational capacity of the network increases quadratically.</p>
</div>
<div class="section" id="id2">
<h3>Links<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p><a href="https://redwood.berkeley.edu/wp-content/uploads/2020/11/kent2020resonator.pdf"> PDF: Resonator networks 2 </a></p>
</div>
</div>
<div class="section" id="integer-factorization-with-compositional-distributed-representations">
<h2>Integer Factorization with Compositional Distributed Representations<a class="headerlink" href="#integer-factorization-with-compositional-distributed-representations" title="Permalink to this headline">¶</a></h2>
<p><img alt="integer_factorization" src="../_images/res_int_factor-220319.png" /></p>
<div class="section" id="id3">
<h3>Summary<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Factoring integers is a well-known problem in computer science and in fact it serves as the back-bone of encryption. This is one of many problems that are “NP” or non-polynomial, which means that you effectively have to use brute-force methods to find the answer. As the problems get harder and harder, these brute-force methods scale exponentially in complexity, which can be virutally impossible to solve.</p>
<p>The problem of integer factorization is fundamentally related to the problem of vector factorization that the resonator network can solve. In this paper, we explain new methods for mapping integers onto VSA vectors based on <span class="xref myst">fractional power encodings</span>. The key is that through this method we can generate VSA vectors that represent integers, and, importantly, the binding of vectors creates a vector representation that is the product of the integers. This means that by solving vector factorization, we can solve integer factorization.</p>
<p>We explain how to set-up the resonator network to solve the factorization of semi-primes and other composite numbers and measure the performance and scaling empirically.</p>
</div>
<div class="section" id="id4">
<h3>Links<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p><a class="reference external" href="http://arxiv.org/abs/2203.00920">arXiv paper</a></p>
<p><a class="reference internal" href="res_semi_primes-220216.html"><span class="doc std std-doc">Factoring semi primes demo</span></a></p>
<!--

## Simple scene understanding with the resonator network

[Template matching with resonator network](resonator_template.ipynb)

-->
<!--
<a href="https://nbviewer.jupyter.org/url/epaxon.github.io/resonator-template-200915.ipynb"> Resonator network with template letter scene </a>
-->
<!--
## Utils
[It's dangerous to go alone!](res_utils.py)

--></div>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Research"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="sparse_binding_demo.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Sparse binding demo – What’s the dollar of mexico?</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="resonator_template.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Factorization of shape, color and location</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
        
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Dr. E. Paxon Frady<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>